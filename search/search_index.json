{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Getting Started","text":"<p>Build AI apps on top of knowledge bases</p> <p>Blue Morpho helps you build AI agents that understand your business context, using ontologies and knowledge graphs.</p> <ol> <li>Connect your data  </li> <li>Build knowledge bases in the form of ontologies and knowledge graphs.  </li> <li>Expose your knowledge bases to internal (in Blue Morpho) or external (through MCP) agents.  </li> <li>Use AI agents to create AI apps for the following use cases: chat with your data, build reports (static or updated when new data arrives), automate workflows.</li> </ol> <p>\u27a1\ufe0f Sign up to Blue Morpho</p>"},{"location":"#problem-we-are-solving","title":"Problem we are solving","text":"<p>Almost all enterprise workflows require gathering information from multiple sources + contextualizing it + applying business logic. Yet simply putting AI agents on top of enterprise systems doesn\u2019t work:</p> <p>\u274c Data is not indexed for agents to find it. This makes it hard for them to locate relevant information. Vector embeddings are unreliable.</p> <p>\u274c It is hard for agents to reconcile information from multiple sources. If systems have ten different definitions of \u201ccustomer\u201d, or \u201cWalmart\u201d shows up in ten different forms, AI agents are doomed anyway.  </p> <p>\u274c Agents lack contextual information about the data. Data does not live in isolation. E.g. for procurement use cases, there is a need to link data across emails, contracts, invoices, approval logs, ERP logs, \u2026  </p> <p>\u274c Agents fail to capture business logic. It\u2019s in people\u2019s heads, applications, documents, \u2026 It doesn\u2019t belong there.  </p>"},{"location":"#what-makes-us-different","title":"What makes us different","text":"<p>\u2705 Reliable metadata filtering, instead of fuzzy vector search.   We do not rely on vector embeddings for agents to locate relevant information. We leverage metadata filtering instead. Basically, LLMs \u201cread\u201d through all input documents and extract vast quantities of metadata derived from business concepts defined in an ontology. Metadata is then used by AI agents to retrieve the right context to perform their tasks, reliably.  </p> <p>\u2705 Entity resolution with LLM as a judge, instead of human review.   We make it very simple to reconcile (\u201cresolve\u201d) information from multiple sources, making all information about a given entity accessible to AI agents from the same place.</p> <p>\u2705 Smart orchestration of LLM calls in controlled environments, instead of fully autonomous agents going wild.   We have a focus on reliability and scalability of our approach. A concrete example for a dashboard building agent: instead of prompting LLMs to \u201ccode a dashboard for XYZ\u201d from scratch, which is prone to many pitfalls making the approach unreliable ; we believe in a parametrized approach. LLMs are given standardized components (charts, buttons, menus) that they can parametrize (with cypher queries to fetch data based on input parameters, or with styling options), making the approach reliable and scalable.  </p>"},{"location":"#features","title":"Features","text":""},{"location":"#build-knowledge-bases-create-an-ontology-knowledge-graph","title":"Build knowledge bases (create an ontology + knowledge graph)","text":"<ul> <li>Ingest and parse documents (pdf, txt)  </li> <li>Create ontologies (classes, properties and relations). Manage the different versions.  </li> <li>Process documents to extract a knowledge graph (entities and their relationships) following your ontology. Resolve (i.e. deduplicate) entities coming from different chunks/documents.  </li> <li>Turn your knowledge graph into a knowledge base, effectively exposing it to AI agents (internal or external).  </li> </ul>"},{"location":"#operate-agents-to-consume-data-in-knowledge-bases-and-act-on-it","title":"Operate agents (to consume data in knowledge bases and act on it)","text":"<ul> <li>Chat with your knowledge bases  </li> <li>Connect to your knowledge bases through Blue Morpho MCP server</li> </ul>"},{"location":"#coming-soon","title":"Coming soon","text":"<p>These features are under active development and will be released in the coming weeks:</p> <ul> <li>Build static or dynamic dashboards on top of your knowledge bases, using natural language  </li> <li>Merge two or more knowledge bases</li> </ul>"},{"location":"#feedback","title":"Feedback","text":"<p>We welcome feedback! Please open an issue, or reach out to hello@getbluemorpho.com.</p>"},{"location":"#socials","title":"Socials","text":"<p>Website</p> <p>LinkedIn</p> <p>GitHub</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This project uses the following open source projects:</p> <ul> <li>Librechat: for chat interface  </li> </ul> <p>We are grateful for their maintainers and contributors.</p>"},{"location":"product/","title":"Platform Overview","text":"<p>The Blue Morpho platform is designed to help you build all kinds of AI agents, apps, and workflows on top of enterprise data.</p>"},{"location":"product/#why-blue-morpho","title":"Why Blue Morpho?","text":"<p>The platform is built with a focus on making enterprise AI:</p> <ul> <li>Scalable: Our Knowledge Layer is a solid foundation to automate not just one workflow, but all your workflows.</li> <li>Reliable: The Knowledge Layer serves as well-structured context to AI agents, making it easy for them to find and use the right data.</li> <li>Widely Accessible: Blue Morpho brings together both technical builders and subject matter experts.</li> </ul>"},{"location":"product/#get-access","title":"Get Access","text":"<p>Ready to begin? Sign up to Blue Morpho and get access to the platform with a trial account.</p>"},{"location":"product/#introductory-concepts","title":"Introductory Concepts","text":""},{"location":"product/#collections","title":"Collections","text":"<p>Raw input data is stored in Collections, which support two types of data:</p> <ul> <li>Unstructured: such as <code>.pdf</code>, <code>.txt</code></li> <li>Structured: such as <code>.csv</code> (coming soon)</li> </ul> <p>Collections typically originate from organizational data sources, either:</p> <ul> <li>Uploaded manually</li> <li>Or (coming soon) ingested programmatically via the Blue Morpho SDK</li> </ul> <p>Connectors to enterprise sources can also be provided upon request.</p>"},{"location":"product/#extraction-runs","title":"Extraction Runs","text":"<p>Extraction Runs extract, transform, and enrich the data from Collections to build the Knowledge Graphs following the format of the Ontologies.</p>"},{"location":"product/#ontologies","title":"Ontologies","text":"<p>Ontologies define business concepts (e.g., <code>Driver</code>, <code>Vehicle</code>, <code>Trip</code>) and their properties (e.g., <code>name</code>, <code>address</code>, <code>SSN</code>).</p>"},{"location":"product/#knowledge-graphs","title":"Knowledge Graphs","text":"<p>A Knowledge Graph connects entities with their relationships. For example, the Driver \"John Doe\" might be linked to his Vehicle and Trips using relations like <code>hasVehicle</code>, <code>hasTrip</code>.</p>"},{"location":"product/#knowledge-bases","title":"Knowledge Bases","text":"<p>Together, the Ontology and Knowledge Graph form a Knowledge Base.</p> <p>Knowledge Bases ensure that your data is:</p> <ul> <li>Well-defined, thanks to the Ontology</li> <li>Linked and resolved, through relations in the Knowledge Graph</li> </ul> <p>This structure makes it easy for AI agents to find and use the right data reliably.</p>"},{"location":"product/#internal-agents","title":"Internal Agents","text":"<p>Blue Morpho includes built-in agents for:</p> <ul> <li>Answering queries based on your data</li> <li>Building reports that auto-update as the Knowledge Base evolves</li> </ul>"},{"location":"product/#external-agents","title":"External Agents","text":"<p>Agents that operate outside of Blue Morpho can connect to its Knowledge Layer using the Model Context Protocol.</p>"},{"location":"product/#next-steps","title":"Next Steps","text":"<p>Functionally, the Blue Morpho platform delivers two core capabilities:</p> <ul> <li>Building Knowledge Bases from structured and unstructured enterprise data  </li> <li>Operating AI agents that reason and act on top of those Knowledge Bases</li> </ul>"},{"location":"product/core%20concepts/1.%20collections/","title":"Collections","text":"<p>Collections are folders that organize your documents within a project in a logical way. Group documents in a collection based on whether you want to extract the same types of information from all of them (as one ontology will apply to all of them).</p>"},{"location":"product/core%20concepts/1.%20collections/#supported-types","title":"Supported Types","text":"<p>Unstructured: - PDF (automatically parsed into markdown format after upload) - TXT</p> <p>Structured: - CSV (coming soon)</p> <p>For high volumes of data (requiring programmatic ingestion) or currently unsupported data types, we can ingest any data for you upon request: hello@getbluemorpho.com.</p>"},{"location":"product/core%20concepts/1.%20collections/#parsing","title":"Parsing","text":"<p>After upload, your PDF documents are automatically parsed into text (more precisely, markdown) format. Title hierarchy and tables (even complex tables with subcolumns, etc.) are properly extracted but you might lose information from charts and pictures.</p> <p>Coming soon: ability to skip parsing and treat raw PDFs. Parsing will still be the recommended option for documents containing mostly text and tables, as it makes further processing more efficient.</p>"},{"location":"product/core%20concepts/1.%20collections/#best-practices","title":"Best Practices","text":"<ul> <li>Use clear, descriptive names and descriptions for collections, as they are passed to AI agents.</li> <li>Group documents in collections based on the types of information you want to extract from them. For example, group financial reports (extract financial metrics, management guidance, ...) or legal contracts (extract clauses, parties, ...) together; but don't mix one financial report and one contract together even if they are linked to the same company. Don't worry, you will be able to make that link later on.</li> </ul>"},{"location":"product/core%20concepts/2.%20ontologies/","title":"Ontologies","text":""},{"location":"product/core%20concepts/2.%20ontologies/#overview","title":"Overview","text":"<p>An Ontology in Blue Morpho is a domain model that defines the types of entities, their properties, and relationships that can be extracted from your documents. Think of it as a blueprint that tells the system what to look for in your data and how to organize the knowledge.</p> <p>The ontology represents your ideal data model. Information from your documents will be extracted, transformed, enriched and mapped to fit this structured model. The goal is not to stick exactly to how information appears in your documents, but to reorganize it into a consistent format that serves your business needs.</p>"},{"location":"product/core%20concepts/2.%20ontologies/#core-concepts","title":"Core Concepts","text":""},{"location":"product/core%20concepts/2.%20ontologies/#what-is-an-ontology","title":"What is an Ontology?","text":"<p>An Ontology is a formal specification that:</p> <ul> <li>Defines Classes (like Person, Organization, Event) present in your data</li> <li>Specifies Properties for each entity type (like name, date, location)</li> <li>Establishes Relationships between different entity types (like a Person attending an Event)</li> <li>Serves as a schema for knowledge extraction and knowledge graph building, ensuring consistent data structure</li> </ul>"},{"location":"product/core%20concepts/2.%20ontologies/#why-use-ontologies","title":"Why Use Ontologies?","text":"<p>Ontologies enable:</p> <ul> <li>Structured Knowledge Extraction: Extract specific information types from your documents, consistently</li> <li>Powerful Querying: The ontology is not only used for extraction, it is also passed as context for AI agents to query your data.</li> </ul>"},{"location":"product/core%20concepts/2.%20ontologies/#ontology-components","title":"Ontology Components","text":""},{"location":"product/core%20concepts/2.%20ontologies/#classes","title":"Classes","text":"<p>Classes define the categories of \"things\" that can be extracted from documents.</p> <p>Examples:</p> <ul> <li><code>Person</code> - Individual people mentioned in documents</li> <li><code>Organization</code> - Companies, institutions, groups</li> <li><code>Location</code> - Places, addresses, geographical areas</li> <li><code>Event</code> - Meetings, conferences, incidents</li> </ul> <p>An instance of a class is an entity. For example, \"Abraham Lincoln\" is an entity belonging to the class <code>Person</code>. </p>"},{"location":"product/core%20concepts/2.%20ontologies/#properties","title":"Properties","text":"<p>Properties define the attributes that entities can have. Each property has:</p> <ul> <li>Name: The property identifier (e.g., \"name\", \"date_of_birth\")</li> <li>Description: What this property represents</li> <li>Data Type: The type of data this property stores</li> <li>Required Status: Whether this property must have a value</li> <li>Possible Values: For enumerated properties, the allowed values</li> </ul> <p>Supported Data Types:</p> <ul> <li><code>str</code> - Text values (e.g., names, descriptions)</li> <li><code>int</code> - Whole numbers (e.g., age, count)</li> <li><code>float</code> - Decimal numbers (e.g., price, percentage)</li> <li><code>bool</code> - True/false values</li> <li><code>date</code> - Calendar dates</li> <li><code>datetime</code> - Date and time combinations</li> <li><code>time</code> - Time values</li> <li><code>duration</code> - Time periods</li> </ul> <p>Enumerated Properties:</p> <p>For <code>str</code> and <code>int</code> properties, you can specify allowed values using the \"enum\" function. </p>"},{"location":"product/core%20concepts/2.%20ontologies/#relationships","title":"Relationships","text":"<p>Relationships define how different entity types connect to each other.</p> <p>Structure:</p> <ul> <li>Source Type: The entity type that initiates the relationship</li> <li>Target Type: The entity type that receives the relationship</li> <li>Predicate: The relationship description</li> </ul> <p>Examples:</p> <ul> <li><code>Person</code> \u2192 <code>works_for</code> \u2192 <code>Organization</code></li> <li><code>Person</code> \u2192 <code>lives_in</code> \u2192 <code>Location</code></li> <li><code>Organization</code> \u2192 <code>located_in</code> \u2192 <code>Location</code></li> <li><code>Event</code> \u2192 <code>attended_by</code> \u2192 <code>Person</code></li> </ul>"},{"location":"product/core%20concepts/2.%20ontologies/#ontology-families-and-versions","title":"Ontology Families and Versions","text":""},{"location":"product/core%20concepts/2.%20ontologies/#ontology-families","title":"Ontology Families","text":"<p>An Ontology Family is a group of related ontology versions that evolve over time. This allows you to iterate on your ontology design while tracking your changes and maintaining backwards compatibility. </p>"},{"location":"product/core%20concepts/2.%20ontologies/#creating-ontology-versions","title":"Creating Ontology Versions","text":"<p>You can create new ontology versions in two ways:</p>"},{"location":"product/core%20concepts/2.%20ontologies/#from-scratch","title":"From Scratch","text":"<p>Start with a completely new ontology design using our ontology editor, or upload a YAML file with the following structure:</p> <pre><code>entity_types:\n- name: Account\n  description: Brokerage account containing financial holdings\n  properties:\n  - name: accountNumber\n    description: unique account identifier\n    type: str\n    is_required: false\n    possible_values: null\n  - name: accountType\n    description: type of account (e.g., Individual, IRA)\n    type: str\n    is_required: true\n    possible_values: null\n  - name: baseCurrency\n    description: base currency using ISO codes (USD, EUR, etc.)\n    type: str\n    is_required: true\n    possible_values: null\n\n- name: FinancialInstrument\n  description: Any financial instrument available for investment\n  properties:\n  - name: symbol\n    description: ticker symbol or unique identifier\n    type: str\n    is_required: true\n    possible_values: null\n  - name: instrumentType\n    description: type of instrument\n    type: str\n    is_required: true\n    possible_values:\n    - stock\n    - bond\n    - etf\n    - mutual fund\n\nrelation_types:\n- subject_name: Account\n  predicate: Contains\n  object_name: Holding\n- subject_name: Holding\n  predicate: Has\n  object_name: FinancialInstrument\n</code></pre>"},{"location":"product/core%20concepts/2.%20ontologies/#from-modifications","title":"From Modifications","text":"<p>Build upon an existing ontology version with incremental changes by simply editing and saving an existing version.</p>"},{"location":"product/core%20concepts/2.%20ontologies/#best-practices","title":"Best Practices","text":""},{"location":"product/core%20concepts/2.%20ontologies/#ontology-design","title":"Ontology Design","text":"<ul> <li>Start simple: Begin with core classes and properties your domain needs</li> <li>Test ontology changes with sample documents and iterate based on extraction quality</li> <li>Use clear, descriptive names and descriptions for types and properties, as these fields are used by AI at extraction and querying times. </li> </ul>"},{"location":"product/core%20concepts/3.%20extraction%20runs/","title":"Extraction Runs","text":""},{"location":"product/core%20concepts/3.%20extraction%20runs/#overview","title":"Overview","text":"<p>Extraction Runs are the core processing job that transforms your document collections into structured knowledge graphs using an ontology. An Extraction Run takes a collection of documents and applies an ontology to systematically extract entities and their relationships, creating a queryable knowledge base.</p> <p>Think of an Extraction Run as an intelligent processing job that reads through all your documents, identifies the information defined by your ontology (people, companies, events, etc.), and organizes everything into a structured graph that you can query and analyze.</p>"},{"location":"product/core%20concepts/3.%20extraction%20runs/#core-concepts","title":"Core Concepts","text":""},{"location":"product/core%20concepts/3.%20extraction%20runs/#what-is-an-extraction-run","title":"What is an Extraction Run?","text":"<p>An Extraction Run is a multi-step pipeline that:</p> <ul> <li>Processes Document Collections: Takes a collection of documents as input</li> <li>Applies an Ontology: Uses your ontology to guide what information to extract</li> <li>Creates Knowledge Graphs: Builds a structured representation of information from your documents</li> </ul> <p>Once you are satisfied with your extraction results, turn them into a Knowledge Base to make them queryable by AI agents. </p>"},{"location":"product/core%20concepts/3.%20extraction%20runs/#extraction-run-pipeline","title":"Extraction Run Pipeline","text":""},{"location":"product/core%20concepts/3.%20extraction%20runs/#pipeline-stages","title":"Pipeline Stages","text":"<p>Every Extraction Run follows a systematic multi-stage pipeline:</p>"},{"location":"product/core%20concepts/3.%20extraction%20runs/#1-chunking-stage-optional","title":"1. Chunking Stage (Optional)","text":"<p>Documents are broken down into manageable pieces.</p> <p>It is recommended to only use chunking for very long documents containing a lot of entities. Start without it, and use it if your extraction feels incomplete!</p> <p>Available chunking methods:</p> <ul> <li>Character-based chunking: Split text into segments with a maximum character count (e.g., 1500 characters)</li> <li>Semantic chunking (coming soon): Use AI to create meaningful content segments based on guidelines you provide</li> </ul>"},{"location":"product/core%20concepts/3.%20extraction%20runs/#2-extraction-stage","title":"2. Extraction Stage","text":"<p>Entity and Relationship Extraction:</p> <ul> <li>Identifies instances of entity types and their relations, as defined in your ontology</li> <li>Configurable with custom extraction guidelines in \"Advanced parameters\"</li> <li>Can extract either from document-level or from chunks resulting from the previous pipeline step. </li> </ul> <p>Advanced Features:</p> <ul> <li>Custom Guidelines: Provide specific instructions. Use it only for guidelines that are very specific to your collection and must not be included directly in your ontology. </li> <li>Think before extraction: Enable detailed reasoning explanations for extractions (the chain-of-thought will appear in the results, useful to learn how the AI interprets your guidelines or documents)</li> <li>Reflect on extracted items: Apply additional validation to extracted entities (the self-reflection will appear in the results)</li> </ul> <p>We use caching techniques so that changing one class in your ontology and re-launching the extraction doesn't recompute all the results for the other untouched classes. The goal is that you work iteratively on your ontology to refine it, based on your extraction results!</p>"},{"location":"product/core%20concepts/3.%20extraction%20runs/#3-deduplication-optional","title":"3. Deduplication (Optional)","text":"<p>Deduplication is a two step process:</p> <ul> <li>First, identify potential candidates.<ul> <li>For obvious duplicates (typically if a strong identifier matches exactly), go straight to the merging step.</li> <li>For not-so-obvious cases (typically if two company names fuzzy match, such as Tesla and Tesla,Inc), trigger an AI review. The AI considers all the entity properties and decides if two entities must be considered duplicates or not. </li> </ul> </li> <li>When two entries have been detected as duplicates, records need to be merged.<ul> <li>If they don't have conflicting properties, merge them.</li> <li>If they have conflicts, use AI to manage them, based on your merge guidelines.</li> </ul> </li> </ul> <pre><code>graph TD\n    B[Step 1: Identify Duplicates Candidates]\n\n    B --&gt; D[Duplicates]\n    B --&gt; E[Potential Duplicates]\n    B --&gt; M[Not Duplicates]\n\n    D --&gt; C[Step 2: Merge Records: Check for Conflicting Properties]\n    E --&gt; G[Trigger AI Review]\n\n    G --&gt; D\n    G --&gt; M\n\n    C --&gt; I[No Conflicts]\n    C --&gt; J[Has Conflicts]\n\n    I --&gt; K[Merge Them]\n    J --&gt; L[Use AI to Manage Conflicts&lt;br/&gt;Based on Merge Guidelines]\n\n    style B fill:#FED766,stroke:#333,stroke-width:2px,color:#000\n    style C fill:#FED766,stroke:#333,stroke-width:2px,color:#000\n    style D fill:#FC5A8F,stroke:#333,stroke-width:2px,color:#fff\n    style E fill:#7061A3,stroke:#333,stroke-width:2px,color:#fff\n    style M fill:#F22FB6,stroke:#333,stroke-width:2px,color:#fff\n    style G fill:#7061A3,stroke:#333,stroke-width:2px,color:#fff\n    style I fill:#FC5A8F,stroke:#333,stroke-width:2px,color:#fff\n    style J fill:#F22FB6,stroke:#333,stroke-width:2px,color:#fff\n    style K fill:#FC5A8F,stroke:#333,stroke-width:2px,color:#fff\n    style L fill:#F22FB6,stroke:#333,stroke-width:2px,color:#fff</code></pre>"},{"location":"product/core%20concepts/3.%20extraction%20runs/#4-results","title":"4. Results","text":"<p>When you are satisfied with the results, you can create a Knowledge Base:</p> <ul> <li>Makes the extraction run results permanent</li> <li>Enables querying and analysis fo your results with AI</li> </ul>"},{"location":"product/core%20concepts/3.%20extraction%20runs/#usage-monitoring","title":"Usage Monitoring","text":"<ul> <li>Check LLM usage insights in extraction run status</li> <li>Smaller chunks and more entity types increase processing costs</li> <li>\"Think before extraction\" and \"Reflect on extracted items\" in the extraction parameters add processing overhead</li> </ul>"},{"location":"product/core%20concepts/3.%20extraction%20runs/#best-practices","title":"Best Practices","text":"<p>Start Simple:</p> <ul> <li>Begin with a small document collection to test your ontology</li> <li>Run extraction on a subset of entity types first</li> <li>Iterate on your ontology based on extraction quality</li> </ul>"},{"location":"product/core%20concepts/4.%20knowledge%20bases/","title":"Knowledge Bases","text":""},{"location":"product/core%20concepts/4.%20knowledge%20bases/#what-are-knowledge-bases","title":"What are Knowledge Bases?","text":"<p>Knowledge Bases are the final, queryable form of your extracted knowledge graphs. They transform the results from your Extraction Runs into permanent, searchable repositories of structured information that can be queried by AI agents.</p>"},{"location":"product/core%20concepts/4.%20knowledge%20bases/#core-concepts","title":"Core Concepts","text":""},{"location":"product/core%20concepts/4.%20knowledge%20bases/#what-is-a-knowledge-base","title":"What is a Knowledge Base?","text":"<p>A Knowledge Base is a structured repository that:</p> <ul> <li>Stores Extracted Knowledge: Contains entities, relationships, and metadata from your processed documents</li> <li>Enables AI Querying: Can be queried using our hosted conversational AI interface from the \"Ask\" tab, or any other conversation UI integrated with Blue Morpho through MCP</li> <li>Supports Analytics: Powers AI-generated dashbooards. </li> </ul>"},{"location":"product/core%20concepts/4.%20knowledge%20bases/#knowledge-base-vs-extraction-run","title":"Knowledge Base vs Extraction Run","text":"Extraction Run Knowledge Base Temporary processing job Permanent data repository Experimental/iterative Production-ready Limited querying in the inteface Available to AI for querying using graph query language"},{"location":"product/core%20concepts/4.%20knowledge%20bases/#create-your-knowledge-base","title":"Create your Knowledge Base","text":"<p>Steps:</p> <ul> <li>Complete Extraction Run</li> <li>Go to \"results\"</li> <li>Click \"Create Knowledge Base\"</li> <li>Knowledge Base becomes available for querying</li> </ul>"},{"location":"product/core%20concepts/4.%20knowledge%20bases/#query-your-knowledge-base","title":"Query Your Knowledge Base","text":"<p>Once your Knowledge Base is ready, you can:</p>"},{"location":"product/core%20concepts/4.%20knowledge%20bases/#query-it-using-our-conversational-interface-available-from-the-ask-section","title":"Query it using our conversational interface available from the \"Ask\" section","text":"<p>Go to \"Ask\" section in the sidebar, name your project and knowledge base of interest, and query it in natural language!</p>"},{"location":"product/core%20concepts/4.%20knowledge%20bases/#expose-it-to-external-agents-through-blue-morpho-model-context-protocol","title":"Expose it to external agents through Blue Morpho Model Context Protocol","text":"<p>See our related tutorial to connect Blue Morpho to other AI tools such as Claude Desktop, Cursor, etc. through Model Context Protocol.</p>"},{"location":"product/core%20concepts/4.%20knowledge%20bases/#use-it-to-power-dasdhboard-analytics","title":"Use it to power dasdhboard analytics","text":"<p>(coming soon)</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/","title":"Model Context Protocol","text":"<p>The Model Context Protocol (MCP) is a standard for connecting Large Language Models (LLMs) to platforms like Blue Morpho. This guide covers how to connect Blue Morpho to the following AI tools using MCP:</p> <ul> <li>Cursor  </li> <li>Claude desktop  </li> </ul> <p>Once connected, your AI assistants can interact with and query your Blue Morpho projects on your behalf. To see a list of available tools, see here. </p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#step-1-create-a-personal-access-token","title":"Step 1: Create a personal access token","text":"<p>First, go to your Blue Morpho settings and create an API key (personal access token). This will be used to authenticate the MCP server with your Blue Morpho account.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#step-2-configure-your-ai-tool","title":"Step 2: Configure your AI tool","text":"<p>MCP-compatible tools can connect to Blue Morpho using the Blue Morpho remote MCP server.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#cursor","title":"Cursor","text":"<p>In Cursor settings, search for \"mcp\". In \"Tools &amp; Integrations\", click on \"New MCP Server\".</p> <p>This creates a <code>mcp.json</code> file:</p> <pre><code>{\n  \"mcpServers\": {\n    \"blue-morpho\": {\n      \"type\": \"url\",\n      \"url\": \"https://app.getbluemorpho.com/mcp/\",\n      \"headers\": {\n        \"X-API-Key\": \"YOUR-API-KEY-HERE\"\n      }\n    }\n  }\n}\n</code></pre> <p>Replace YOUR-API-KEY-HERE with your Blue Morpho API key (or preferably, use environment variables). </p> <p>Save the file. Navigate back to Settings \u2192 MCP. You should see a green active status once connected.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#claude-desktop","title":"Claude desktop","text":"<p>Navigate to Settings \u2192 Developer \u2192 Edit Config:</p> <pre><code>{\n  \"mcpServers\": {\n    \"blue-morpho\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"https://app.getbluemorpho.com/mcp/\",\n        \"--header\",\n        \"X-API-Key: YOUR-API-KEY-HERE\"\n      ]\n    }\n  }\n}\n</code></pre> <p>Replace YOUR-API-KEY-HERE with your Blue Morpho API key (or preferably, use environment variables). </p> <p>Restart Claude. Navigate back to Settings \u2192 Developer \u2192 Edit Config. You should see your running MCP connection.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#step-3-use-blue-morpho-mcp-tools","title":"Step 3: Use Blue Morpho MCP tools","text":"<p>Once your AI tool is connected to Blue Morpho via MCP, you can immediately begin issuing commands to interact with your projects.</p> <p>Try asking your AI assistant to <code>list Blue Morpho projects</code> to make sure everything is working properly!</p> <p>Learn more about the Blue Morpho tools accessible through MCP below.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#project-and-knowledge-base-management","title":"Project and Knowledge Base Management","text":""},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#list_projects","title":"<code>list_projects</code>","text":"<p>Lists all projects in the application.</p> <p>Parameters: None</p> <p>Usage: Useful for discovering available projects to work with.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#list_knowledge_bases","title":"<code>list_knowledge_bases</code>","text":"<p>Lists all knowledge bases within a specific project.</p> <p>Parameters: - <code>project_id</code></p> <p>Usage: Helps you find the knowledge bases available for analysis.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#document-management","title":"Document Management","text":""},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#list_knowledge_base_documents","title":"<code>list_knowledge_base_documents</code>","text":"<p>Lists the original documents used to build a knowledge base.</p> <p>Parameters: - <code>project_id</code> - <code>knowledge_base_id</code></p> <p>Usage: Shows you what source documents were processed to create the graph.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#get_knowledge_base_document_urls","title":"<code>get_knowledge_base_document_urls</code>","text":"<p>Provides download URLs for specific documents.</p> <p>Parameters: - <code>project_id</code> - <code>knowledge_base_id</code> - <code>document_id</code></p> <p>Returns: Pre-signed AWS S3 URLs (expire after 30 minutes).</p> <p>Usage: Essential for accessing the original document content.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#graph-structure-and-ontology","title":"Graph Structure and Ontology","text":""},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#get_knowledge_base_ontology_version","title":"<code>get_knowledge_base_ontology_version</code>","text":"<p>Retrieves the ontology (schema) for a knowledge base.</p> <p>Parameters: - <code>project_id</code> - <code>knowledge_base_id</code></p> <p>Usage: Critical: Must be called before any graph querying to understand the data structure.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#graph-querying-and-search","title":"Graph Querying and Search","text":""},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#compute_cypher_query","title":"<code>compute_cypher_query</code>","text":"<p>Executes Cypher queries against the graph database.</p> <p>Parameters: - <code>cypher_query</code> - <code>project_id</code> - <code>knowledge_base_id</code></p> <p>Notes: - Uses Memgraph\u2019s Cypher implementation (openCypher standard). - Prerequisite: Retrieve ontology first.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#search_node_in_graph","title":"<code>search_node_in_graph</code>","text":"<p>Searches for nodes matching a query within the graph.</p> <p>Parameters: - <code>search_query</code> - <code>project_id</code> - <code>knowledge_base_id</code> - <code>node_type_name</code> (optional, searches all types if not specified) - <code>max_number_results</code> (optional, max 30)</p> <p>Limitations: - Cannot search <code>SourceDocument</code> nodes. - Prerequisite: Retrieve ontology first.</p>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#key-workflow","title":"Key Workflow","text":"<ol> <li>Discovery: </li> <li>List projects \u2192 List knowledge bases</li> <li>Schema Understanding: </li> <li>Get ontology (mandatory before querying)</li> <li>Data Exploration: </li> <li>Search nodes or run Cypher queries</li> <li>Document Access: </li> <li>List documents \u2192 Get document URLs for original sources</li> </ol>"},{"location":"product/core%20concepts/5.%20setup%20blue%20morpho%20mcp/#important-notes","title":"Important Notes","text":"<ul> <li>Ontology First: Always retrieve and display the ontology before performing any graph operations.  </li> <li>Time Limits: Document URLs expire after 30 minutes.  </li> <li>Query Limits: Node searches return a maximum of 30 results.  </li> <li>Cypher Compatibility: Uses openCypher standard (no APOC or Neo4j-specific functions).  </li> <li>Source Documents: Use the document URL tool instead of querying <code>SourceDocument</code> nodes directly.</li> </ul>"},{"location":"tutorials/analyze-etfs/","title":"Analyze ETFs","text":"<p>Information on ETFs such as fees, structure, or ESG criteria is often buried in unstructured documents. Blue Morpho lets you model the key data points once and extract them consistently across all documents, making comparison and analysis easy.</p> <p>In this tutorial, we will answer questions about three different ETFs using their KID and Factsheet documents.</p>"},{"location":"tutorials/analyze-etfs/#step-1-create-a-project","title":"Step 1: Create a project","text":"<p>Every workflow in Blue Morpho begins with a project. A project organizes your collections, ontologies, extractions, and knowledge bases so all related work stays in one place.</p> <ol> <li>Go to Projects.  </li> <li>Click New Project.  </li> <li>Enter a name (e.g. \u201cETF Analysis\u201d) and a short goal (e.g. \u201cAutomate analysis of multiple ETFs\u201d).</li> <li>Click Create.</li> </ol>"},{"location":"tutorials/analyze-etfs/#step-2-create-a-collection","title":"Step 2: Create a collection","text":"<p>A collection is a set of documents analyzed with the same ontology. You can upload PDFs (automatically parsed into text) or TXT files (ingested directly). Parsing time depends on the file size and number of documents.</p> <ol> <li>Go to Collections.  </li> <li>Click New Collection.  </li> <li>Enter a name (e.g. \u201cETF Documents\u201d) and a short description (e.g. \u201cFactsheets and KIDs for ETFs\u201d).  </li> <li>Upload the 6 sample PDFs provided in this ZIP file for this tutorial.</li> <li>Click Create</li> </ol> <p>Note: The dataset includes both KID and Factsheet PDFs for three ETFs. These are for demonstration only and not for financial use.</p>"},{"location":"tutorials/analyze-etfs/#step-3-create-an-ontology","title":"Step 3: Create an ontology","text":"<p>An ontology defines the structure of your data: what entities exist, their properties, and how they relate. Think of it as the blueprint for organizing knowledge extracted from your documents.</p> <p>ETF documents include hundreds of data points, from detailed portfolio holdings to complex derivative exposures. In this tutorial, we\u2019ll focus on a few essential elements to keep the model clear, practical, and easy to follow.</p> <p>We will therefore create the following objects:</p> <p>Entities</p> <ul> <li>ETF: Name, ISIN, management company, benchmark index, replication method, ESG approach, fees, SRRI, and trading details.  </li> <li>Sector: Basic investment categories (e.g. \u201cHealth Care\u201d, \u201cTechnology\u201d). SectorExposure: Links ETFs to sectors, with attributes for date and weight percentage (e.g. \u201c15.3% in Healthcare\u201d).</li> </ul> <p>Relationships:</p> <ul> <li>ETF \u2192 has_sector_exposure \u2192 SectorExposure  </li> <li>SectorExposure \u2192 references \u2192 Sector</li> </ul> <p>This allows queries such as: \u201cWhat\u2019s the average technology exposure across all ETFs?\u201d</p> <p>Create the Ontology in Blue Morpho</p> <p>You can create an ontology manually or use the ontology assistant. For this tutorial, we\u2019ve already prepared one for you to import.</p> <ol> <li>Go to Ontologies.  </li> <li>Click New Ontology.  </li> <li>Enter a name and description (e.g. \u201cETF analysis ontology\u201d).  </li> <li>Choose Import from YAML file and upload this ontology template: ETF analysis ontology </li> <li>Click Create</li> </ol>"},{"location":"tutorials/analyze-etfs/#explore-your-ontology","title":"Explore your ontology","text":"<p>After importing, you\u2019ll see your ontology as a list of entities and relationships.</p> <p>You can add short natural language descriptions to each entity, property and relation to capture their meaning in your business context. These descriptions enrich the ontology with contextual knowledge, helping the agent give grounded answers. Blue Morpho also uses them during extraction to accurately identify and map the right information from your documents, even when wording or terminology varies.</p> <p>Review the entities and their properties, especially those related to ETFs.</p> <p></p>"},{"location":"tutorials/analyze-etfs/#step-4-run-an-extraction","title":"Step 4: Run an extraction","text":"<p>Now let\u2019s extract data from your ETF documents based on your ontology.</p> <ol> <li>Go to Extraction Runs.  </li> <li>Click New Run.  </li> <li>Add a name (e.g. \u201cETF extraction\u201d) and a description (e.g. \u201cExtract key ETF information from Factsheets and KIDs\u201d).  </li> <li>Select your Ontology (\u201cETF analysis ontology\u201d) and your Collection (\u201cETF documents\u201d)  </li> <li>Click Create </li> <li>Add an Extraction step with the default settings and click Extract.</li> </ol>"},{"location":"tutorials/analyze-etfs/#review-your-extraction-results","title":"Review your extraction results","text":"<p>The Results view lists all extracted ETF information from your Factsheets and KIDs, along with the related sectors and the SectorExposure entities linking ETFs to sectors.</p> <p>For example, search for \u201ciShares Core MSCI World\u201d to compare the data Blue Morpho extracted from its KID and Factsheet. </p> <p>This step helps you verify that Blue Morpho correctly extracted the information, created the entities and relationships, and lets you adjust the ontology if needed.</p> <p>Once the extraction results look correct, move on to deduplication:</p> <ul> <li>Scroll back up and click Deduplication (optional)</li> </ul>"},{"location":"tutorials/analyze-etfs/#deduplicate-extraction-results","title":"Deduplicate extraction results","text":"<p>Deduplication merges identical entities extracted from multiple sources, preventing duplicates in your knowledge base.</p> <p>In this tutorial, you\u2019ll notice duplicates for:</p> <ul> <li>ETFs since information comes from both Factsheets and KIDs  </li> <li>Sectors since a single sector may appear in multiple ETFs</li> </ul> <p>To deduplicate:</p> <ol> <li>Click Add class to deduplicate entities </li> <li>Select ETF and Sector</li> </ol> <p>In this case, the deduplication process is straightforward, and Blue Morpho can handle it without additional configuration:</p> <ol> <li>Click on Generate rules without adding any guidelines  </li> <li>Click on Deduplicate </li> </ol>"},{"location":"tutorials/analyze-etfs/#review-your-deduplication-results","title":"Review your deduplication results","text":"<p>Scroll down to review the deduplication results.</p> <p>Using the \u201ciShares Core MSCI World\u201d example, you\u2019ll now see a single ETF entity combining properties from both source entities (the KID and the Factsheet). The resulting entity references both original documents.</p> <p></p> <p>For Sector entities, you\u2019ll notice that Blue Morpho merged variations such as \u201cFinancial services\u201d and \u201cFinance\u201d into a single standardized \u201cFinancials\u201d sector. This ensures consistent analysis of sector exposure across all ETFs.</p> <p>You can guide the deduplication process by defining preferred final names in the \u201cGuidelines for detecting duplicates.\u201d Example: \u201cDeduplicate all financial services\u2013related sectors into a single sector named \u2018Financial services.\u2019\u201d </p>"},{"location":"tutorials/analyze-etfs/#step-5-create-a-knowledge-base","title":"Step 5: Create a Knowledge Base","text":"<p>Once extraction and deduplication look correct, turn them into a Knowledge Base so you can query them.</p> <ol> <li>In the Extraction Results view, click Create Knowledge Base.  </li> <li>Add a name (e.g. \u201cETF analysis KB\u201d) and a description (e.g. \u201cKnowledge Base ETF information\u201d).  </li> <li>Click Create.</li> </ol>"},{"location":"tutorials/analyze-etfs/#step-6-query-your-knowledge-base","title":"Step 6: Query your Knowledge Base","text":"<p>With your Knowledge Base ready, you can now ask questions in plain language. Each query is automatically translated into a structured search based on your ontology and the data extracted from your ETF Factsheets and KIDs.</p> <ol> <li>Go to Knowledge Bases.  </li> <li>Select your Knowledge Base (\u201cETF analysis KB\u201d).   </li> <li>At the top right, click on \u201cAsk\u201d to start a chat with your knowledge base</li> </ol>"},{"location":"tutorials/analyze-etfs/#example-1-find-etfs","title":"Example 1 - Find ETFs","text":"<p>Quickly identify which ETFs match your specific criteria, even if you don\u2019t use the exact terminology.</p> <pre><code>Show me the ETF with the best environmental characteristics, limited risks and requiring minimum management from me\n</code></pre> <p></p>"},{"location":"tutorials/analyze-etfs/#example-2-analyze-portfolio-sector-exposure","title":"Example 2 - Analyze portfolio sector exposure","text":"<p>Compare the sector exposure of your selected ETFs using the latest available data.</p> <pre><code>Compare sector exposure across all my ETFs\n</code></pre> <p></p>"},{"location":"tutorials/analyze-etfs/#example-3-compare-fees-between-etfs","title":"Example 3 - Compare fees between ETFs","text":"<p>Compare specific cost criteria across all ETFs in your portfolio or selection.</p> <pre><code>Compare total fees across all ETFs.\nFormat as a table with columns: ETF | Entry fees | Transaction fees | Other fees | Exit fee\n</code></pre> <p> You can also ask follow-up questions to explore the details:</p> <pre><code>Show me the detailed fee structure for BNP PARIBAS EASY MSCI EMU SRI PAB.\n</code></pre> <p></p>"},{"location":"tutorials/analyze-etfs/#next-steps","title":"Next steps","text":"<p>You now have a working ETF analysis workflow.</p> <p>You can:</p> <ul> <li>Add new ETF Factsheets and KIDs to your collection to expand your analysis.  </li> <li>Extend the ontology to include more dimensions, such as geographic exposure, equity exposure, currency risk, or protection mechanisms.</li> </ul> <p>Continue exploring Blue Morpho with these next steps</p> <ul> <li>Analyze other financial products: Adapt the ontology to study corporate bonds, mutual funds, or other instruments.  </li> <li>Consolidate investment portfolios: Follow the Investment portfolios tutorial to combine financial reports into a single knowledge base.  </li> <li>Integrate through MCP: Query your Knowledge Base directly from your own environment..</li> </ul>"},{"location":"tutorials/analyze-pitch-decks/","title":"Analyze Pitch Decks","text":"<p>VC analysts review dozens of pitch decks every week, often repeating the same tasks: extracting the core details of a startup, checking whether it fits the fund\u2019s investment thesis, identifying risks, comparing it to similar companies, and preparing insights for partners. In this tutorial, you\u2019ll learn how to automate much of that workflow using Blue Morpho.</p> <p>We\u2019ll work through a set of sample pitch decks and show how to transform raw PDFs into structured insights, apply deal\u2011fit logic, detect risks, and query everything through a knowledge base. </p> <p>The focus is on pitch deck analysis, but the same approach applies to many other workflows, including investment memo analysis, dealflow reporting, and startup benchmarking.</p>"},{"location":"tutorials/analyze-pitch-decks/#step-1-create-a-project","title":"Step 1: Create a Project","text":"<p>A project keeps your collections, ontology, extraction runs, and knowledge bases organized in one place.</p> <ol> <li>Go to Projects.  </li> <li>Click New Project.  </li> <li>Add a name (e.g., \u201cPitch Deck Analysis\u201d).  </li> <li>Add a description (e.g., \u201cA project to analyze startup pitch decks.\u201d).  </li> <li>Click Create.</li> </ol>"},{"location":"tutorials/analyze-pitch-decks/#step-2-create-a-collection","title":"Step 2: Create a Collection","text":"<p>A Collection is a folder of documents processed with the same ontology. Upload your pitch decks here so Blue Morpho can parse and analyze them. For this tutorial, the dataset contains several well-known public startup pitch decks from different stages and industries.</p> <ol> <li>Go to Collections.  </li> <li>Click New Collection.  </li> <li>Add a name (e.g., \u201cPitch Deck Dataset\u201d).  </li> <li>Add a description (e.g., \u201cA set of startup pitch decks.\u201d).  </li> <li>Upload the sample pitch decks. Download here.   </li> <li>Click Create.</li> </ol>"},{"location":"tutorials/analyze-pitch-decks/#step-3-create-an-ontology-with-the-ai-assistant","title":"Step 3: Create an Ontology with the AI Assistant","text":"<p>In this step, you will teach Blue Morpho how to understand pitch decks the way a VC analyst does. By the end, you\u2019ll have an ontology that:</p> <ul> <li>Extracts structured information about each startup,  </li> <li>Applies your investment thesis to classify deal fit,  </li> <li>And can evolve over time through version updates.</li> </ul>"},{"location":"tutorials/analyze-pitch-decks/#phase-1-create-the-base-ontology","title":"Phase 1: Create the base ontology","text":"<p>The ontology defines the core concepts you want Blue Morpho to extract from your pitch decks. Instead of building it manually, you can describe your needs in natural language and let the AI Ontology Assistant generate the first version.</p> <ol> <li>Go to Ontologies.  </li> <li>Click New Ontology.  </li> <li>Add a name (e.g., \u201cPitch Deck Ontology\u201d).  </li> <li>Add a description (e.g., \u201cStructure for extracting insights from pitch decks.\u201d).  </li> <li>Select AI Ontology Assistant.</li> </ol> <p>When the assistant asks what the ontology should capture, describe the key elements you want extracted from each pitch deck. This helps the assistant generate the right structure for your use case.</p> <p>Prompt to use:</p> <pre><code>I want to analyze startup pitch decks like a VC analyst.\n\nI need the ontology to extract and structure the most important elements from any pitch deck so I can compare companies, identify red flags, and generate investment memos.\n\nThe ontology should capture:\n\n* Company basics: name, industry, business model, geography, stage  \n* Product &amp; solution: problem, solution, demo screenshots, GTM, pricing  \n* Market data: TAM, SAM, SOM, target customer, market trends  \n* Traction &amp; metrics: revenue, MRR, growth rate, churn, CAC, LTV, users, retention  \n* Team: founders, roles, background, previous exits  \n* Competition: competitors, differentiation, moat  \n* Financials: round type, funding ask, use of funds\n</code></pre>"},{"location":"tutorials/analyze-pitch-decks/#review-your-generated-ontology","title":"Review your generated ontology","text":"<p>Once generated, review the proposed classes and properties and check whether they match your workflow:</p> <ul> <li>Are the classes, properties and relations clear?   </li> <li>Should some classes be merged or simplified?  </li> <li>Are any important properties missing?</li> </ul> <p>You can refine your ontology at any time. Tell the AI assistant what you want to adjust, and it will save those changes as a new version so you can track how your ontology evolves.</p>"},{"location":"tutorials/analyze-pitch-decks/#phase-2-enrich-your-ontology-with-business-context","title":"Phase 2: Enrich your ontology with business context","text":"<p>After creating the base structure, you can teach the ontology how you actually evaluate startups. This is where domain knowledge becomes part of the system.</p> <p>1. Identify only the primary company</p> <p>Pitch decks mention many companies\u2014competitors, customers, partners. Only the startup being pitched should be extracted as a <code>Company</code>. Everything else should map to other concepts. We can ask the assistant to create this rule. </p> <p>Prompt to use:</p> <pre><code>Ensure the Company class is populated only with the primary startup of the deck and not with any other companies mentioned.\n</code></pre> <p>2. Add deal-fit logic based on your investment thesis</p> <p>To help Blue Morpho evaluate whether each startup aligns with your fund\u2019s investment criteria, you can add business rules that assess deal-fit directly from the extracted information. This allows the system to classify opportunities automatically and explain the reasoning in natural language.</p> <p>Prompt to use: <pre><code>I want the ontology to automatically judge whether a startup matches our investment preferences. Please add a \u2018investment fit\u2019 concept that the system can fill in using rules based on what we look for, and have it explain the reasoning in plain language.\n\nWhat we look for:\n\n* Early B2B SaaS companies  \n* Seed to Series A  \n* Some early traction  \n* Strong technical founders  \n* Raising between \u20ac300k and \u20ac2M.\n</code></pre></p> <p>3. Track risks inferred from extracted data</p> <p>Finally, you can extend your ontology to detect risks automatically based on the information extracted from each pitch deck. This turns risk analysis into an automated layer that highlights missing data, weak signals, or unrealistic claims.</p> <p>Instead of manually identifying potential issues, you can let Blue Morpho infer them by creating a <code>Risk</code> concept and defining simple rules\u2014such as flagging missing traction, unclear business models, unrealistic market sizes, or weak founder backgrounds.</p> <p>Prompt to use: <pre><code>Use the Risk concept to automatically flag potential issues (e.g., missing traction, unclear business model, unrealistic TAM, weak team signals) and set a risk type and severity based on what you extract from the pitch deck.\n</code></pre></p>"},{"location":"tutorials/analyze-pitch-decks/#step-4-run-an-extraction","title":"Step 4: Run an Extraction","text":"<p>Now it\u2019s time to extract the key insights from each pitch deck using your ontology.</p>"},{"location":"tutorials/analyze-pitch-decks/#steps","title":"Steps","text":"<ol> <li>Go to Extraction Runs.  </li> <li>Click New Run.  </li> <li>Add a name (e.g., \u201cPitch Deck Analysis Extraction\u201d).  </li> <li>Add a description (e.g., \u201cExtract structured insights from the pitch decks.\u201d).  </li> <li>Select your Ontology and your Collection.  </li> <li>Click Create.  </li> <li>Review the default settings and click Extract.  </li> <li>Skip Deduplication (not needed for pitch decks).  </li> <li>Open Results.</li> </ol>"},{"location":"tutorials/analyze-pitch-decks/#validate-results","title":"Validate results","text":"<p>Use the filters at the top of the Results view to select Airbnb-pitch-deck.pdf under Documents and Company under Classes. This will show the extracted Company entity along with all its related information.</p> <p>Check that the core details look correct (industry, business model, geography, stage) and that the linked Product, Market, Traction, or Funding entities reflect what\u2019s in the deck. Make sure the Investment-Fit assessment makes sense based on your thesis, and review any risks the system inferred.</p> <p>If something looks off, go back to the AI Ontology Assistant, refine your instructions, and rerun the extraction. A couple of quick iterations is normal until the results look right.</p>"},{"location":"tutorials/analyze-pitch-decks/#step-5-create-a-knowledge-base","title":"Step 5: Create a Knowledge Base","text":"<p>Once you\u2019re happy with the extraction results, the next step is to make them queryable.</p> <ol> <li>From the Extraction Results view, click Create Knowledge Base.  </li> <li>Add a name (e.g., \u201cPitch Deck Analysis KB\u201d).  </li> <li>Add a description (e.g., \u201cA knowledge base with all extracted pitch deck insights.\u201d).  </li> <li>Click Create.</li> </ol>"},{"location":"tutorials/analyze-pitch-decks/#step-6-ask-questions","title":"Step 6: Ask Questions","text":"<p>With your Knowledge Base ready, you can now interact with all your pitch decks through natural language.</p> <ol> <li>Go to Knowledge Bases.  </li> <li>Open your Pitch Deck Analysis KB.  </li> <li>Click Ask to start a chat.</li> </ol>"},{"location":"tutorials/analyze-pitch-decks/#example-1-overview-of-all-startups","title":"Example 1 \u2013 Overview of all startups","text":"<p>Get a quick, structured snapshot of every company in your dataset. <pre><code>Give me an overview of all startups with their company details in a clean table\n</code></pre> </p>"},{"location":"tutorials/analyze-pitch-decks/#example-2-analyze-products-and-value-propositions","title":"Example 2 \u2013 Analyze products and value propositions","text":"<p>See how each startup positions its product and the value it delivers to customers. <pre><code>Analyze the product and value proposition for Airbnb\n</code></pre> </p>"},{"location":"tutorials/analyze-pitch-decks/#example-3-evaluate-investmentfit","title":"Example 3 \u2013 Evaluate investment\u2011fit","text":"<p>Use the business logic you added earlier to understand which startups match your thesis. <pre><code>How startups fit our investment thesis, and why? Output in a clean table view\n</code></pre> </p>"},{"location":"tutorials/analyze-pitch-decks/#example-4-identify-risks","title":"Example 4 \u2013 Identify risks","text":"<p>Surface red flags automatically inferred from each pitch deck. <pre><code>What are the top risks identified for Airbnb?\n</code></pre> </p>"},{"location":"tutorials/analyze-pitch-decks/#example-5-generate-a-partnerready-summary","title":"Example 5 \u2013 Generate a partner\u2011ready summary","text":"<p>Produce a clean brief for partner meetings or investment committees. <pre><code>Create a partner\u2011ready summary about each startup\n</code></pre> </p>"},{"location":"tutorials/analyze-pitch-decks/#bonus-queries","title":"Bonus queries","text":"<ul> <li>Which companies have strong technical founders?  </li> <li>Show all startups with missing traction or incomplete data.  </li> <li>Which companies have unrealistic market claims?  </li> <li>Find all companies raising more than \u20ac2M.</li> </ul> <p>Use follow\u2011up questions to drill deeper, just like you would in a real investment discussion.</p>"},{"location":"tutorials/analyze-pitch-decks/#step-7-next-steps","title":"Step 7: Next steps","text":"<p>You now have a complete workflow for analyzing pitch decks with Blue Morpho: upload decks, model your investment logic as an ontology, extract structured data, and query everything through a Knowledge Base.</p> <p>Here are some ideas for what to try next:</p> <ul> <li>Upload your own pitch decks and refine the ontology to match your fund\u2019s thesis.  </li> <li>Extend the ontology with additional concepts, such as unit economics or references to market benchmarks.  </li> <li>Explore how this same approach can be applied to other workflows such as ETF analysis, NDA compliance reviews, or consolidating investment portfolios.</li> </ul>"},{"location":"tutorials/automate%20nda%20review/","title":"Automate NDA Compliance","text":"<p>Legal teams spend hours reviewing NDAs for the same checklist of rules: is it mutual, does it preserve ownership, does it specify an approved jurisdiction. With Blue Morpho, you can automate this process by modeling those rules once and applying them consistently across every contract.</p> <p>In this tutorial, you\u2019ll follow along with three sample NDAs to see exactly how it works.</p>"},{"location":"tutorials/automate%20nda%20review/#step-1-create-a-project","title":"Step 1: Create a project","text":"<p>All your work in Blue Morpho starts inside a project. A project groups together collections, ontologies, extractions, and knowledge bases, so everything related to one use case stays in the same workspace.</p> <ol> <li>Go to Projects.  </li> <li>Click New Project.  </li> <li>Add a Name (e.g. \u201cNDA Compliance\u201d). </li> <li>Add a Description (e.g. \u201cAutomate compliance checks across our NDAs\u201d).</li> <li>Click Create.</li> </ol>"},{"location":"tutorials/automate%20nda%20review/#step-2-create-a-collection","title":"Step 2: Create a collection","text":"<p>A collection is a folder of documents processed with the same ontology. You can upload files as PDF, which are automatically parsed into text (markdown), or as TXT, which are ingested directly. Parsing may take a few minutes depending on the number and size of the files.</p> <ol> <li>Go to Collections.  </li> <li>Click New Collection.  </li> <li>Add a Name (e.g. \u201cNDA Compliance Docs\u201d).</li> <li>Add a Description (e.g. \u201cCollection of active NDAs signed with partners.\u201d).  </li> <li>Download the sample dataset and upload the NDAs files. </li> <li>Click Create</li> </ol> <p>Note: The dataset contains three different NDAs: one fully compliant, one problematic with multiple red flags, and one edge case that looks fine at first but includes unusual clauses.</p> <p>These NDAs are synthetic examples generated from the open-source Universal NDA template. They are for demonstration purposes only, not for legal use.</p>"},{"location":"tutorials/automate%20nda%20review/#_1","title":"Automate NDA Compliance","text":""},{"location":"tutorials/automate%20nda%20review/#step-3-create-an-ontology","title":"Step 3: Create an ontology","text":"<p>In this use case, the ontology works a bit differently. Instead of modeling entities and their relationships, it serves as a set of compliance rules.</p> <p>Each provision you want to verify, such as mutuality, ownership, or choice of law, becomes a class. The properties within each class define how compliance is checked and where the supporting evidence is found in the NDA.</p> <p>Since each clause can be evaluated independently, relationships between classes are not needed. The ontology functions as a checklist of rules, each connected to the exact text that supports the result.</p> <ol> <li>Go to Ontologies.  </li> <li>Click New Ontology.  </li> <li>Add a Name (e.g. \u201cNDA Compliance Ontology\u201d). </li> <li>Add a Description (e.g. \u201cOntology to check NDA provisions against internal rules\u201d).  </li> <li>Click Create</li> <li>Click Import from YAML</li> <li>Download the sample NDA ontology and import the YAML file. </li> <li>Click Create</li> </ol>"},{"location":"tutorials/automate%20nda%20review/#explore-your-ontology","title":"Explore your ontology","text":"<p>After importing, you\u2019ll see your ontology displayed as a list of provisions. Each one represents a class (e.g. ChoiceOfLawProvision) with properties that define how compliance is determined.</p> <p></p> <ul> <li>supporting_elements: captures the text from the NDA that justifies the decision.  </li> <li>is_compliant: encodes your business rule (e.g. which jurisdictions are approved).  </li> <li>jurisdiction_specified: captures the jurisdiction explicitly named in the NDA.</li> </ul>"},{"location":"tutorials/automate%20nda%20review/#step-4-run-an-extraction","title":"Step 4: Run an extraction","text":"<p>With your NDAs and ontology ready, the next step is to apply the rules and extract structured results.</p> <ol> <li>Go to Extraction Runs.  </li> <li>Click New Run.  </li> <li>Add a Name (e.g. \u201cNDA Compliance Extraction\u201d).</li> <li>Add a Description (e.g. \u201cRun to check NDA provisions against compliance ontology\u201d).  </li> <li>Select your Ontology (\u201cNDA Compliance Ontology\u201d).</li> <li>Select your Collection (\u201cNDA Compliance Docs\u201d)  </li> <li>Click Create  </li> </ol> <p>Configure the pipeline</p> <ol> <li>Skip Chunking - not needed for NDAs.  </li> <li>Add an Extraction step - keep the default settings. </li> <li>Click Extract.  </li> <li>Click on Deduplication</li> <li>Skip Deduplication - not needed for NDAs.  </li> <li>Click on Results </li> </ol>"},{"location":"tutorials/automate%20nda%20review/#review-your-results","title":"Review your results","text":"<p>The results view lists all extracted provisions from your NDAs, showing each provision\u2019s class, properties and source document. This is where you can see how your ontology was applied across all documents.</p> <p>Use this view to validate your extraction. Check that the results follow the rules defined in your ontology and that the supporting text accurately reflects the clause in the NDA. If something doesn\u2019t look right, adjust the ontology and rerun the extraction to improve accuracy.</p> <p></p>"},{"location":"tutorials/automate%20nda%20review/#step-5-create-a-knowledge-base","title":"Step 5: Create a knowledge base","text":"<p>After reviewing your extraction results, create a knowledge base to make them queryable.</p> <ol> <li>In the Extraction results view, click Create knowledge base.  </li> <li>Add a Name (e.g. \u201cNDA Compliance KB\u201d).</li> <li>Add a Description (e.g. \u201cKnowledge Base of NDA compliance results\u201d).  </li> <li>Click Create.</li> </ol>"},{"location":"tutorials/automate%20nda%20review/#step-6-query-your-knowledge-base","title":"Step 6: Query your knowledge base","text":"<p>With your knowledge base ready, you can now ask questions in plain language. Each query is translated into a structured search based on your ontology and the supporting text extracted from your NDAs.</p> <ol> <li>Go to Knowledge Bases.  </li> <li>Select your knowledge base (\u201cNDA Compliance KB\u201d).   </li> <li>At the top right, click on \u201cAsk\u201d to start a chat with your knowledge base</li> </ol>"},{"location":"tutorials/automate%20nda%20review/#example-1-view-overall-compliance","title":"Example 1 - View overall compliance","text":"<p>See at a glance which NDAs are compliant overall and which are not.</p> <pre><code>Show me all NDAs with their overall compliance status. \nFormat as a table with columns: NDA | Overall Status\n</code></pre> <p></p>"},{"location":"tutorials/automate%20nda%20review/#example-2-audit-a-single-nda","title":"Example 2 - Audit a single NDA","text":"<p>Drill down into one NDA and check clause-by-clause compliance.</p> <pre><code>Show me the compliance status of all provisions for the DataCore NDA. \nFormat as a table with columns: Provision | Compliant? | Supporting Text.\n</code></pre> <p></p>"},{"location":"tutorials/automate%20nda%20review/#example-3-compare-a-specific-clause","title":"Example 3 - Compare a specific clause","text":"<p>Compare a specific provision across all NDAs in your portfolio.</p> <pre><code>Show me the compliance status of the Choice Of Law for all NDAs.\nFormat as a table with columns: NDA | Jurisdiction | Compliant? | Supporting Text.\n</code></pre> <p></p>"},{"location":"tutorials/automate%20nda%20review/#example-4-explain-a-non-compliant-clause","title":"Example 4 - Explain a non-compliant clause","text":"<p>Ask why a specific clause fails compliance and see the supporting text.</p> <pre><code>Why is the Non Solicit clause in the DataCore NDA not compliant? \nFormat as table\n</code></pre> <p></p>"},{"location":"tutorials/automate%20nda%20review/#example-5-suggest-edits-to-make-a-clause-compliant","title":"Example 5 - Suggest edits to make a clause compliant","text":"<p>Ask the system to propose text changes that would make a clause meet your internal compliance rules.</p> <pre><code>Suggest how to rewrite the Choice of Law clause in the BetaTech NDA \nto make it compliant with our approved jurisdictions.\n</code></pre> <p></p>"},{"location":"tutorials/automate%20nda%20review/#next-steps","title":"Next steps","text":"<p>You now have a working NDA compliance workflow: every clause checked against your rules, with supporting text to explain each result. The same approach can streamline other reviews too, from GDPR clauses in contracts to eligibility checks in RFPs or diligence signals in M&amp;A.</p> <p>\u2192 Try it with your own NDAs: adapt the ontology and rules to your policies.</p> <p>\u2192 Explore the investment portfolios tutorial: consolidate reports into a knowledge base.</p> <p>\u2192 Integrate through MCP: connect your knowledge base to other tools.</p>"},{"location":"tutorials/consolidate%20investment%20portfolios/","title":"Analyze Investment Portfolios","text":"<p>If you have different investment account types (IRAs, 401(k)s, taxable accounts) or use different brokers, you know how tedious it is to get a complete picture of your holdings. This tutorial shows you how to use Blue Morpho to:</p> <ul> <li>Consolidate identical holdings across multiple portfolios for a unified view</li> <li>Perform aggregations, calculations, and analysis</li> <li>Create interactive dashboards to manage your holdings</li> </ul> <p>This use case demonstrates the strength of our approach, as these results cannot be obtained using any state-of-the-art model out of the box.</p> <p>Similar Use Cases</p> <p>This approach works for any use case where you need to structure and homogenize data for structured queries (essentially, \"turn data into tables and make it queryable\"). Similar examples include:</p> <ul> <li>Ledger consolidation: Extract journal entries, accounts, and amounts from PDF exports to unify multiple accounting systems</li> <li>Portfolio management for Private Equity: Create portfolio management applications and automate reporting to LPs</li> <li>Asset management &amp; maintenance: Merge asset registries from different plants or fleets to enable fleet-wide analytics</li> <li>Healthcare records analysis: Structure patient information, diagnoses, procedures, and billing codes from PDF medical records for analysis</li> </ul>"},{"location":"tutorials/consolidate%20investment%20portfolios/#step-1-upload-your-portfolio-statements","title":"Step 1: Upload Your Portfolio Statements","text":"<p>Go to the Collections section and create a new collection containing your investment statements (PDFs). For this tutorial, we'll use sample statements from Interactive Brokers. The statements cover three different brokerage accounts:</p> <ul> <li>A traditional IRA</li> <li>A Roth IRA  </li> <li>A regular taxable account</li> </ul> <p>You can download them here.</p> <p>Upon upload, Blue Morpho will automatically parse these documents, transforming them into raw text while preserving table structures to feed them to LLMs in the next steps.</p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#step-2-define-your-ontology","title":"Step 2: Define Your Ontology","text":"<p>When consolidating multiple portfolios, key concepts (ontology classes) include <code>Account</code>, <code>Cash Balance</code>, <code>Holding</code>, and <code>Financial Instrument</code>.</p> <p></p> <p>Navigate to the Ontologies section and create a new ontology. You can name it \"consolidate portfolios\". After the creation, click on \"New version\": you can either use the editor or download our example ontology in YAML format and import it directly into Blue Morpho.</p> <p>You should see the following classes: </p> <p></p> <p></p> <p></p> <p></p> <p>And the following relationships:</p> <p></p> <p>If desired, you can refine the ontology further by modeling <code>Transactions</code>, <code>Dividends</code>, and other financial concepts.</p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#step-3-run-an-extraction","title":"Step 3: Run an Extraction","text":"<p>Navigate to the Extraction Runs section and start a new run using your ontology and document collection.</p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#31-chunking","title":"3.1 Chunking","text":"<p>This step is not needed for portfolio statements (it's reserved for very long documents). Navigate directly to Extraction. </p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#32-extraction","title":"3.2 Extraction","text":"<p>The default settings work well and there is no need to configure advanced parameters. Click \"Extract\" to perform the extraction.</p> <p>At this stage, you should have extracted 3 <code>Accounts</code>, 192 <code>Financial Instruments</code>, 184 <code>Holdings</code> and 7 <code>Cash Balances</code>.</p> <p>As you can see in the results section, relations have also been extracted. For example, this particular <code>Holding</code> is linked with one <code>Financial Instrument</code> and one <code>Account</code>:</p> <p></p> Advanced considerations: How Blue Morpho Handles Different Broker Data Formats <p>Different brokers format data inconsistently:</p> <ul> <li>Some classify interest payments or dividends as transactions, others don't</li> <li>Some show sell transaction amounts as negative quantities, others as positive</li> <li>Date formats, currency symbols, and field names vary across platforms</li> </ul> <p>What you can do:</p> <ul> <li>Use descriptive class definitions: For example, if you only want stock/bond transactions (excluding interest payments or dividends), state this in your <code>Transaction</code> class description</li> </ul> <p></p> <ul> <li>Use descriptive property definitions: For example, if you want sell transaction amounts as positive quantities, specify that all <code>quantity</code> and <code>amount</code> values should be positive numbers and add a <code>transaction_type</code> property that is either \"sell\" or \"buy\".</li> </ul> <p></p> <p>Blue Morpho will automatically transform inconsistent broker data into clean, standardized entities that follow your exact specifications. </p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#33-deduplication","title":"3.3 Deduplication","text":"<p>This critical step consolidates duplicate entities across your multiple accounts. For example, Amazon (AMZN) stock is held in all three accounts, so it was extracted three times as separate <code>Financial Instrument</code> entities. While it's correct to maintain three separate <code>Holding</code> entities (one for each account), you want to create a single <code>Financial Instrument</code> entity for AMZN.</p> <p>This resolved entity will link to multiple <code>Holding</code> entities, which themselves remain linked to their respective <code>Accounts</code>, maintaining account relationships.</p> <p>To do this, click on \"Add class to deduplicate entities\" and select <code>Financial Instrument</code>.</p> <p>Using natural language, simply state how you want duplicates to be identified. In this case, it's straightforward: \"Merge instruments if they have the same symbol or CUSIP.\"</p> <p></p> <p>Click on \"Generate rules\" and you should see a set of conditions displayed on the right.</p> <p><code>Financial Instruments</code> that meet these conditions will be considered duplicates and auto-resolved. If there are conflicting properties (which shouldn't occur in this simple example), an LLM will resolve them based on best judgment, or based on merge guidelines you can also provide as \"Advanced parameters\".</p> <p>Clicking \"Deduplicate\" performs the consolidation.</p> <p>After deduplication, you will have 386 entities before deduplication and 289 entities after.</p> <p>This step keeps account-specific holdings separate (for tax tracking or individual portfolio performance) while enabling portfolio-wide analysis, as we'll see in the next step. See for example \"BKNG\" <code>Financial Instrument</code> that is linked to 3 <code>Holdings</code> and originates from 3 source entities: </p> Advanced considerations: Sophisticated Deduplication <p>This step is also useful in more complex cases. For example, \"Tesla\" and \"Tesla, Inc.\" can be reconciled using fuzzy matching on the corresponding property, plus AI review to make the final decision (a tutorial dedicated to complex entity resolution will come soon). </p> <p>Once complete, go to Results and create your Knowledge Base: this becomes your queryable, unified investment database ready for analysis!</p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#step-4-query-your-consolidated-portfolio","title":"Step 4: Query Your Consolidated Portfolio","text":"<p>This is where it gets the most exciting! You can now run sophisticated queries across your unified portfolio data.</p> <p>Navigate to Ask section. This will open a conversational interface. You should land on our dedicated \"Knowledge Base Agent\". If not, select it from the menu as in the screenshot below:</p> <p></p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#select-your-knowledge-base","title":"Select your Knowledge Base","text":"<p>\"Project \u2018YOUR-PROJECT\u2019, knowledge base \u2018YOUR-KNOWLEDGE-BASE\u2019</p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#query-summary-statistics","title":"Query: Summary statistics","text":"<p>Let's first verify that we can replicate summary statistics present in the account statements to confirm accuracy: </p> <p>Compute allocation (in terms of market value and % of total) by type of financial instrument, for each account. Take the cash position into account.</p> <p>The agent should return:</p> <p></p> <p>You should have the exact same metrics that you can find in the accounts statements. For example, in the traditional IRA account statement, we can find:</p> <p></p> <p>The numbers match (although the aggregated information is of course not in the knowledge base), that's a good start! Now we can perform other queries.</p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#query-top-holdings-of-the-combined-portfolios","title":"Query: Top holdings of the combined portfolios","text":"<p>Now let\u2019s aggregate across accounts.</p> <p>What are the top 10 financial instruments by holding market value of the consolidated portfolio? For each instrument, indicate in how many accounts it can be found.</p> <p></p> <p>Perfect!</p> <p>When provided with the three account statements, both the latest OpenAI and Anthropic models will fail at this query and other advanced queries (despite appearing confident in their responses), which outlines the strength of our approach. </p> <p>In fact, our approach is the only approach that scales well with large portfolios, different brokerage accounts using varying data structures and conventions, more sophisticated ontologies, and additional documents in the collection.</p>"},{"location":"tutorials/consolidate%20investment%20portfolios/#step-5-create-a-dashboard-coming-soon","title":"Step 5: Create a Dashboard (Coming Soon)","text":"<p>Blue Morpho allows you to build dashboards to visualize your consolidated portfolio. Our dashboards are:</p> <ul> <li> <p>Interactive: They feature filters, dropdown menus, and other interactive elements</p> </li> <li> <p>Dynamic: Adding documents to the collection (not yet supported) will iteratively grow the Knowledge Base and automatically populate the dashboards with fresh data</p> </li> </ul> <p>Simply describe what you want in natural language, and our system will generate the appropriate visualizations!</p> <p>Here are the chart types you can use:</p> <ul> <li>Area Chart</li> <li>Area Stacked Chart  </li> <li>Bar Chart</li> <li>Bar Stacked Chart</li> <li>Line Chart</li> <li>Pie Chart</li> <li>Scatter Chart</li> </ul>"}]}